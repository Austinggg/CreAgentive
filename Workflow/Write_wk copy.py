from autogen_agentchat.teams import DiGraphBuilder, GraphFlow
from Agent.WriteAgent import create_agents
import os
import json
from datetime import datetime
from Resource.tools.strip_markdown_codeblock import strip_markdown_codeblock
from Resource.llmclient import LLMClientManager


class WritingWorkflow:
    def __init__(self, model_client, chapters_dir, save_dir='Resource/story'):
        """
        å†™ä½œå·¥ä½œæµåˆå§‹åŒ–

        :param model_client: Autogen æ¨¡å‹å®¢æˆ·ç«¯å®ä¾‹ï¼Œç”¨äºåˆ›å»ºå’Œè°ƒç”¨å„ Agent
        :param chapters_dir: ç« èŠ‚ JSON æ–‡ä»¶æ‰€åœ¨ç›®å½•è·¯å¾„
        :param save_dir: å†™ä½œè¾“å‡ºç›®å½•ï¼Œé»˜è®¤ 'Resource/story'
        """
        self.model_client = model_client
        self.chapters_dir = chapters_dir
        self.save_dir = save_dir

        # å„ Agent å ä½
        self.digger = None           # æŒ–å‘åˆ¤æ–­ Agent
        self.digger_search = None    # æŒ–å‘æ£€ç´¢ Agent
        self.recall = None           # å›å¿†åˆ¤æ–­ Agent
        self.recall_search = None    # å›å¿†æ£€ç´¢ Agent
        self.combiner = None         # åˆå¹¶ Agent
        self.writer = None           # å†™ä½œ Agent

        # GraphFlow ç»„ä»¶
        self.graph = None
        self.graph_flow = None

    def _create_agents(self):
        """
        åˆ›å»ºæ‰€æœ‰æ‰€éœ€ Agent å®ä¾‹
        è¿”å› diggerAgentã€digger_searchã€recallAgentã€recall_searchã€combinerAgentã€writer
        """
        agents = create_agents(self.model_client)
        self.digger = agents['diggerAgent']
        self.digger_search = agents['digger_search']
        self.recall = agents['recallAgent']
        self.recall_search = agents['recall_search']
        self.combiner = agents['combinerAgent']
        self.writer = agents['writer']

    def _build_graph(self, all_files):
        """
        æ„å»º Autogen å¹¶è¡Œæµç¨‹å›¾ï¼ˆDiGraphï¼‰

        - recall -> recall_search -> combiner
        - digger -> digger_search -> combiner
        - combiner -> writer

        æ¡ä»¶ï¼š
        - recallåˆ†æ”¯ï¼šéç¬¬ä¸€ç« ä¸” recallAgent è¾“å‡º 'YES'
        - diggeråˆ†æ”¯ï¼šéæœ€åä¸€ç« ä¸” diggerAgent è¾“å‡º 'YES'
        """
        builder = DiGraphBuilder()
        # æ·»åŠ èŠ‚ç‚¹
        builder.add_node(self.recall)
        builder.add_node(self.recall_search)
        builder.add_node(self.digger)
        builder.add_node(self.digger_search)
        builder.add_node(self.combiner)
        builder.add_node(self.writer)

        first_file = all_files[0]
        last_file = all_files[-1]
        # å›å¿†åˆ¤æ–­
        builder.add_edge(
            self.recall, self.recall_search,
            condition=(
                f"'{first_file}' not in msg.meta['current_file'] "
                "and 'YES' in msg.to_model_text()"
            )
        )
        # æŒ–å‘åˆ¤æ–­
        builder.add_edge(
            self.digger, self.digger_search,
            condition=(
                f"'{last_file}' not in msg.meta['current_file'] "
                "and 'YES' in msg.to_model_text()"
            )
        )
        # æ£€ç´¢ç»“æœæ±‡æ€»åˆ° combiner
        builder.add_edge(self.recall_search, self.combiner)
        builder.add_edge(self.digger_search, self.combiner)
        # combiner -> writer
        builder.add_edge(self.combiner, self.writer)

        self.graph = builder.build()

    def _save_text(self, content, filename):
        os.makedirs(self.save_dir, exist_ok=True)
        path = os.path.join(self.save_dir, filename)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“¦ å†™ä½œæˆæœå·²ä¿å­˜è‡³ï¼š{path}")

    def run(self, current_file, article_type="novel"):
        """
        æ‰§è¡Œ Autogen GraphFlow å†™ä½œæµç¨‹

        æ­¥éª¤ï¼š
        1. éªŒè¯ç±»å‹
        2. åŠ è½½å½“å‰ç« èŠ‚ JSON
        3. åˆ›å»º Agents
        4. æ„å»ºæµç¨‹å›¾
        5. è¿è¡Œ GraphFlow
        6. æå–å†™ä½œè¾“å‡ºå¹¶ä¿å­˜
        """
        # 1. éªŒè¯ç±»å‹
        t = article_type.lower()
        assert t in ['novel', 'script'], "æ–‡ç« ç±»å‹å¿…é¡»ä¸º 'novel' æˆ– 'script'"
        # 2. åŠ è½½ JSON
        files = sorted(os.listdir(self.chapters_dir))
        assert current_file in files, "æŒ‡å®šæ–‡ä»¶ä¸å­˜åœ¨"
        current_path = os.path.join(self.chapters_dir, current_file)
        with open(current_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # 3. åˆ›å»º Agents
        self._create_agents()
        # 4. æ„å»ºå¹¶è¡Œæµç¨‹å›¾
        self._build_graph(files)

        # 5. æ„å»ºå¹¶è¿è¡Œ GraphFlow
        self.graph_flow = GraphFlow(
            participants=[
                self.recall,
                self.digger,
                self.recall_search,
                self.digger_search,
                self.combiner,
                self.writer
            ],
            graph=self.graph
        )
        result = self.graph_flow.run(
            meta={
                'current_file': current_file,
                'chapter_data': data
            }
        )

        # 6. æå–å†™ä½œ Agent è¾“å‡º
        writer_msgs = [m for m in result.messages if m.source == self.writer.name]
        text = strip_markdown_codeblock(writer_msgs[-1].content)

        # ä¿å­˜
        ext = '.md' if t == 'script' else '.txt'
        filename = f"out_{t}_{datetime.now().strftime('%Y%m%d_%H%M%S')}{ext}"
        self._save_text(text, filename)
        return text


if __name__ == '__main__':

    # è·å– DeepSeek-v3 æ¨¡å‹å®¢æˆ·ç«¯
    client = LLMClientManager.get_client("DeepSeek-v3")

    # å®ä¾‹åŒ–å¹¶è¿è¡Œå†™ä½œå·¥ä½œæµ
    wf = WritingWorkflow(client, './Resource/chapters')
    print(wf.run('chapter_02.json', 'novel'))
