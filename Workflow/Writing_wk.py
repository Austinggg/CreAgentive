import os
import json
import atexit
from datetime import datetime
from neo4j import GraphDatabase
from Resource.tools.strip_markdown_codeblock import strip_markdown_codeblock
from Agent.WriteAgent import create_agents
from Resource.tools.extract_llm_content import extract_llm_content
from autogen_agentchat.messages import TextMessage
from autogen_agentchat.agents import AssistantAgent
#from Resource.tools.extract_last_text_content import extract_last_text_content
import re

class WritingWorkflow:
    """
    å†™ä½œä½œæ–‡æ¡£å·¥ä½œæµç±»ï¼Œè´Ÿè´£åè°ƒå„æ™ºèƒ½ä½“å®Œæˆä»ç« èŠ‚åˆ†æåˆ°æœ€ç»ˆæ–‡æœ¬ç”Ÿæˆçš„å…¨æµç¨‹
    æ ¸å¿ƒåŠŸèƒ½ï¼šå¤„ç†ç« èŠ‚JSONæ•°æ®ã€è°ƒç”¨æ™ºèƒ½ä½“è¿›è¡Œä¼ç¬”æŒ–æ˜ä¸å›å¿†æ£€ç´¢ã€æ•´åˆæ•°æ®å¹¶ç”Ÿæˆå°è¯´/å‰§æœ¬
    """

    def __init__(self, model_client, chapters_dir, save_dir=None, neo4j_uri="bolt://localhost:7687",
                 neo4j_user="neo4j", neo4j_password=None):
        """
        åˆå§‹åŒ–å·¥ä½œæµå‚æ•°

        :param model_client: è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆå¦‚DeepSeekï¼‰ï¼Œç”¨äºæ™ºèƒ½ä½“è°ƒç”¨
        :param chapters_dir: ç« èŠ‚JSONæ–‡ä»¶å­˜æ”¾ç›®å½•ï¼ˆè¾“å…¥ç›®å½•ï¼‰
        :param save_dir: ç”Ÿæˆæ–‡æœ¬çš„ä¿å­˜ç›®å½•ï¼ˆè¾“å‡ºç›®å½•ï¼‰ï¼Œé»˜è®¤åœ¨Resource/story
        :param neo4j_uri: Neo4jæ•°æ®åº“è¿æ¥URI
        :param neo4j_user: Neo4jç”¨æˆ·å
        :param neo4j_password: Neo4jå¯†ç ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
        """
        self.model_client = model_client
        self.chapters_dir = chapters_dir
        self.save_dir = save_dir or os.path.join("Resource", "story")

        # åˆå§‹åŒ–Neo4jè¿æ¥
        self.neo4j_driver = self._init_neo4j(neo4j_uri, neo4j_user, neo4j_password)
        atexit.register(self._close_neo4j)  # ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨å…³é—­è¿æ¥

        # æ™ºèƒ½ä½“åˆå§‹åŒ–æ ‡è®°
        self.agents_initialized = False

    def _init_neo4j(self, uri, user, password):
        """
        åˆå§‹åŒ–Neo4jæ•°æ®åº“è¿æ¥é©±åŠ¨

        :return: Neo4jé©±åŠ¨å®ä¾‹ï¼Œè¿æ¥å¤±è´¥åˆ™è¿”å›None
        """
        if not password:
            print("âš ï¸ Neo4jå¯†ç æœªæä¾›ï¼Œè·³è¿‡è¿æ¥åˆå§‹åŒ–")
            return None

        try:
            driver = GraphDatabase.driver(
                uri,
                auth=(user, password),
                max_connection_lifetime=30 * 60,  # è¿æ¥æœ€å¤§å­˜æ´»æ—¶é—´30åˆ†é’Ÿ
                connection_timeout=15  # è¿æ¥è¶…æ—¶æ—¶é—´15ç§’
            )
            # æµ‹è¯•è¿æ¥
            with driver.session() as session:
                session.run("RETURN 1")
            print("âœ… Neo4jè¿æ¥åˆå§‹åŒ–æˆåŠŸ")
            return driver
        except Exception as e:
            print(f"âŒ Neo4jè¿æ¥å¤±è´¥: {str(e)}")
            return None

    def _close_neo4j(self):
        """å…³é—­Neo4jè¿æ¥ï¼ˆç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨è°ƒç”¨ï¼‰"""
        if self.neo4j_driver:
            try:
                self.neo4j_driver.close()
                print("âœ… Neo4jè¿æ¥å·²å®‰å…¨å…³é—­")
            except Exception as e:
                print(f"âš ï¸ Neo4jå…³é—­å¼‚å¸¸: {str(e)}")

    def _create_agents(self):
        """
        åˆ›å»ºå¹¶åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„æ™ºèƒ½ä½“
        æ™ºèƒ½ä½“åˆ—è¡¨ï¼š
        - memAgent: å†…å­˜ç®¡ç†æ™ºèƒ½ä½“
        - diggerAgent: ä¼ç¬”æŒ–æ˜æ™ºèƒ½ä½“
        - recallAgent: å›å¿†æ£€ç´¢æ™ºèƒ½ä½“
        - novel_writer: å°è¯´å†™ä½œæ™ºèƒ½ä½“
        - script_writer: å‰§æœ¬å†™ä½œæ™ºèƒ½ä½“
        """
        if self.agents_initialized:
            return  # é¿å…é‡å¤åˆå§‹åŒ–

        agents = create_agents(self.model_client)
        self.memAgent = agents["memAgent"]
        self.diggerAgent = agents["diggerAgent"]
        self.recallAgent = agents["recallAgent"]
        self.novel_writer = agents["novel_writer"]
        self.script_writer = agents["script_writer"]
        self.agents_initialized = True
        print("âœ… æ‰€æœ‰æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")

    def _validate_article_type(self, article_type="novel"):
        """
        éªŒè¯å†™ä½œç±»å‹åˆæ³•æ€§

        :param article_type: æ–‡ç« ç±»å‹ï¼Œæ”¯æŒ"novel"ï¼ˆå°è¯´ï¼‰æˆ–"script"ï¼ˆå‰§æœ¬ï¼‰
        :return: å°å†™çš„åˆæ³•ç±»å‹
        :raises AssertionError: ç±»å‹ä¸åˆæ³•æ—¶æŠ›å‡º
        """
        article_type = article_type.lower()
        assert article_type in ["novel", "script"], "æ–‡ç« ç±»å‹å¿…é¡»ä¸º 'novel' æˆ– 'script'"
        return article_type

    def _load_json(self, file_path):
        """
        åŠ è½½å¹¶è§£æJSONæ–‡ä»¶

        :param file_path: JSONæ–‡ä»¶è·¯å¾„
        :return: è§£æåçš„å­—å…¸æ•°æ®
        :raises FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨æ—¶
        :raises ValueError: JSONæ ¼å¼é”™è¯¯æ—¶
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        except json.JSONDecodeError:
            raise ValueError(f"JSONæ ¼å¼æ— æ•ˆ: {file_path}")

    def _load_current_chapter(self, current_chapter_file):
        """
        åŠ è½½å½“å‰ç« èŠ‚çš„JSONæ•°æ®

        :param current_chapter_file: ç« èŠ‚æ–‡ä»¶åï¼ˆå¸¦.jsonæ‰©å±•åï¼‰
        :return: ç« èŠ‚æ•°æ®å­—å…¸ï¼Œæ ¼å¼å‚è€ƒchapter1.json
        """
        current_path = os.path.join(self.chapters_dir, current_chapter_file)
        print(f"ğŸ“– åŠ è½½ç« èŠ‚æ–‡ä»¶: {current_path}")
        return self._load_json(current_path)

    def _get_sorted_chapter_files(self):
        """è·å–æŒ‰ç« èŠ‚é¡ºåºæ’åºçš„æ‰€æœ‰ç« èŠ‚æ–‡ä»¶"""
        all_files = [
            f for f in os.listdir(self.chapters_dir)
            if f.endswith('.json') and f.startswith(('chapter', 'Chapter'))
        ]
        # æŒ‰ç« èŠ‚æ•°å­—æ’åºï¼ˆå‡è®¾æ–‡ä»¶åæ ¼å¼ä¸ºchapterX.jsonï¼‰
        return sorted(all_files, key=lambda x: int(re.search(r'(\d+)', x).group(1)))

    def _query_neo4j_event(self, event_id):
        """å¢å¼ºç‰ˆNeo4jæŸ¥è¯¢ï¼Œè·å–äº‹ä»¶æ‰€æœ‰å±æ€§"""
        if not self.neo4j_driver:
            return None

        try:
            with self.neo4j_driver.session() as session:
                result = session.run(
                    """
                    MATCH (e:Event {id: $event_id})
                    RETURN properties(e) AS event_data
                    """,
                    event_id=event_id
                ).single()
                return result["event_data"] if result else None
        except Exception as e:
            print(f"âš ï¸ Neo4jæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return None

    # åœ¨Writing_wk.pyä¸­æ·»åŠ ä»¥ä¸‹æ–¹æ³•

    def _filter_chapter_events(self, chapter_data):
        """ä»ç« èŠ‚æ•°æ®ä¸­æå–äº‹ä»¶ä¿¡æ¯"""
        return {
            "chapter": chapter_data.get("chapter"),
            "events": chapter_data.get("events", [])
        }

    # åœ¨Writing_wk.pyä¸­æ·»åŠ /ä¿®æ”¹ä»¥ä¸‹æ–¹æ³•

    def _filter_events_only(self, chapter_data):
        """ä»ç« èŠ‚æ•°æ®ä¸­åªæå–äº‹ä»¶ä¿¡æ¯"""
        return {
            "chapter": chapter_data.get("chapter"),
            "events": chapter_data.get("events", [])
        }

    async def _need_recall_and_load(self, current_data, current_chapter_file):
        print("\n" + "=" * 50)
        print("ğŸ” å¼€å§‹å›å¿†äº‹ä»¶æ£€ç´¢æµç¨‹")
        print(f"å½“å‰ç« èŠ‚: {current_data.get('chapter', 'æœªçŸ¥')}")

        all_files = self._get_sorted_chapter_files()
        try:
            current_index = all_files.index(current_chapter_file)
        except ValueError:
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {current_chapter_file}")
            return {"need_recall": "No", "positions": []}, []

        if current_index == 0:
            print("â„¹ï¸ æç¤ºï¼šç¬¬ä¸€ç« æ— éœ€å›å¿†")
            return {"need_recall": "No", "positions": []}, []

        # æ„å»ºè¾“å…¥æ•°æ®
        input_data = {
            "current_chapter": {
                "chapter": current_data["chapter"],
                "events": current_data.get("events", [])
            },
            "past_chapters": []
        }

        # åŠ è½½å‰åºç« èŠ‚
        print("\nğŸ“‚ åŠ è½½çš„å‰åºç« èŠ‚:")
        for fname in all_files[:current_index]:
            chapter_data = self._load_json(os.path.join(self.chapters_dir, fname))
            past_events = chapter_data.get("events", [])
            input_data["past_chapters"].append({
                "chapter": chapter_data["chapter"],
                "events": past_events
            })
            print(f"- ç« èŠ‚ {chapter_data['chapter']}: {len(past_events)}ä¸ªäº‹ä»¶")

        # è°ƒç”¨å›å¿†Agent
        print("\nğŸ¤– å›å¿†Agentè¾“å…¥:")
        print(json.dumps(input_data, indent=2, ensure_ascii=False))

        recall_result = await self.recallAgent.a_run(task=input_data)
        raw_output = extract_llm_content(recall_result)

        print("\nğŸ’¡ å›å¿†AgentåŸå§‹è¾“å‡º:")
        print(raw_output)

        try:
            recall_resp = json.loads(strip_markdown_codeblock(raw_output))
            print("\nâœ… è§£æåçš„å›å¿†ç»“æœ:")
            print(json.dumps(recall_resp, indent=2, ensure_ascii=False))

            recall_events = []
            if recall_resp.get("need_recall") == "Yes":
                print("\nğŸ” éœ€è¦å›å¿†çš„äº‹ä»¶:")
                for pos in recall_resp.get("positions", []):
                    event_id = pos["id"]
                    print(f"- äº‹ä»¶ID: {event_id} | åç§°: {pos.get('name', 'æœªçŸ¥')}")

                    event_details = self._query_neo4j_event(event_id)
                    if event_details:
                        print(f"  æŸ¥è¯¢åˆ°çš„å±æ€§: {list(event_details.keys())}")
                        recall_events.append(event_details)

            return recall_resp, recall_events
        except Exception as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return {"need_recall": "No", "positions": []}, []

    async def _need_dig_and_load(self, current_data, current_chapter_file):
        print("\n" + "=" * 50)
        print("ğŸ”® å¼€å§‹ä¼ç¬”äº‹ä»¶æ£€ç´¢æµç¨‹")
        print(f"å½“å‰ç« èŠ‚: {current_data.get('chapter', 'æœªçŸ¥')}")

        all_files = self._get_sorted_chapter_files()
        try:
            current_index = all_files.index(current_chapter_file)
        except ValueError:
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {current_chapter_file}")
            return {"need_dig": "No", "positions": []}, []

        if current_index == len(all_files) - 1:
            print("â„¹ï¸ æç¤ºï¼šæœ€åä¸€ç« æ— éœ€ä¼ç¬”")
            return {"need_dig": "No", "positions": []}, []

        # æ„å»ºè¾“å…¥æ•°æ®
        input_data = {
            "current_chapter": {
                "chapter": current_data["chapter"],
                "events": current_data.get("events", [])
            },
            "future_chapters": []
        }

        # åŠ è½½åç»­ç« èŠ‚
        print("\nğŸ“‚ åŠ è½½çš„åç»­ç« èŠ‚:")
        for fname in all_files[current_index + 1:]:
            chapter_data = self._load_json(os.path.join(self.chapters_dir, fname))
            future_events = chapter_data.get("events", [])
            input_data["future_chapters"].append({
                "chapter": chapter_data["chapter"],
                "events": future_events
            })
            print(f"- ç« èŠ‚ {chapter_data['chapter']}: {len(future_events)}ä¸ªäº‹ä»¶")

        # è°ƒç”¨ä¼ç¬”Agent
        print("\nğŸ¤– ä¼ç¬”Agentè¾“å…¥:")
        print(json.dumps(input_data, indent=2, ensure_ascii=False))

        dig_result = await self.diggerAgent.a_run(task=input_data)
        raw_output = extract_llm_content(dig_result)

        print("\nğŸ’¡ ä¼ç¬”AgentåŸå§‹è¾“å‡º:")
        print(raw_output)

        try:
            dig_resp = json.loads(strip_markdown_codeblock(raw_output))
            print("\nâœ… è§£æåçš„ä¼ç¬”ç»“æœ:")
            print(json.dumps(dig_resp, indent=2, ensure_ascii=False))

            dig_events = []
            if dig_resp.get("need_dig") == "Yes":
                print("\nğŸ” éœ€è¦ä¼ç¬”çš„äº‹ä»¶:")
                for pos in dig_resp.get("positions", []):
                    event_id = pos["id"]
                    print(f"- äº‹ä»¶ID: {event_id} | åç§°: {pos.get('name', 'æœªçŸ¥')}")

                    event_details = self._query_neo4j_event(event_id)
                    if event_details:
                        print(f"  æŸ¥è¯¢åˆ°çš„å±æ€§: {list(event_details.keys())}")
                        dig_events.append(event_details)

            return dig_resp, dig_events
        except Exception as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return {"need_dig": "No", "positions": []}, []

    async def _combine_plans(self, current_data, dig_events, recall_events):
        """
        å®Œæ•´æ•´åˆå½“å‰ç« èŠ‚æ•°æ®ä¸ä¼ç¬”/å›å¿†äº‹ä»¶

        å‚æ•°:
            current_data: å½“å‰ç« èŠ‚å®Œæ•´æ•°æ®(åŒ…å«persons/relationships/scenes/eventsç­‰)
            dig_events: ä»åç»­ç« èŠ‚æå–çš„å®Œæ•´ä¼ç¬”äº‹ä»¶åˆ—è¡¨
            recall_events: ä»å‰åºç« èŠ‚æå–çš„å®Œæ•´å›å¿†äº‹ä»¶åˆ—è¡¨

        è¿”å›:
            æ•´åˆåçš„å®Œæ•´ç« èŠ‚æ•°æ®ï¼Œä¿æŒåŸå§‹ç»“æ„å¹¶æ·»åŠ dig_eventså’Œrecall_events
        """
        print("\n" + "=" * 50)
        print("ğŸ§© å¼€å§‹å®Œæ•´æ•°æ®æ•´åˆ")

        # 1. æ·±æ‹·è´å½“å‰ç« èŠ‚æ•°æ®
        combined = json.loads(json.dumps(current_data))

        # 2. æ·»åŠ å®Œæ•´äº‹ä»¶ä¿¡æ¯
        combined["dig_events"] = []
        combined["recall_events"] = []

        # 3. å¤„ç†ä¼ç¬”äº‹ä»¶ï¼ˆä»åç»­ç« èŠ‚æå–çš„å®Œæ•´äº‹ä»¶ï¼‰
        for event in dig_events or []:
            if isinstance(event, dict):
                # è¡¥å……å¿…è¦å­—æ®µï¼ˆå¦‚æœNeo4jæŸ¥è¯¢ç»“æœç¼ºå°‘ï¼‰
                event.setdefault("source_type", "dig")
                combined["dig_events"].append(event)

        # 4. å¤„ç†å›å¿†äº‹ä»¶ï¼ˆä»å‰åºç« èŠ‚æå–çš„å®Œæ•´äº‹ä»¶ï¼‰
        for event in recall_events or []:
            if isinstance(event, dict):
                event.setdefault("source_type", "recall")
                combined["recall_events"].append(event)

        # 5. æ‰“å°è¯¦ç»†æ•´åˆæŠ¥å‘Š
        self._print_integration_details(combined)

        return combined

    def _print_integration_details(self, data):
        """æ‰“å°è¯¦ç»†çš„æ•´åˆç»“æœ"""
        print("\nğŸ“Š æ•´åˆè¯¦æƒ…æŠ¥å‘Š")
        print(f"=== ç« èŠ‚ {data['chapter']} ===")

        # åŸå§‹æ•°æ®ç»Ÿè®¡
        print("\nğŸ“Œ åŸå§‹æ•°æ®:")
        print(f"- äººç‰©: {len(data.get('persons', []))}")
        print(f"- å…³ç³»: {len(data.get('relationships', []))}")
        print(f"- åœºæ™¯: {len(data.get('scenes', []))}")
        print(f"- ä¸»äº‹ä»¶: {len(data.get('events', []))}")

        # ä¼ç¬”äº‹ä»¶è¯¦æƒ…
        print("\nğŸ”® ä¼ç¬”äº‹ä»¶:")
        for event in data.get("dig_events", [])[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ªå®Œæ•´äº‹ä»¶
            print(json.dumps(event, indent=2, ensure_ascii=False))

        # å›å¿†äº‹ä»¶è¯¦æƒ…
        print("\nğŸ“œ å›å¿†äº‹ä»¶:")
        for event in data.get("recall_events", [])[:2]:
            print(json.dumps(event, indent=2, ensure_ascii=False))

        # å®Œæ•´æ•°æ®ç»“æ„éªŒè¯
        print("\nâœ… æœ€ç»ˆæ•°æ®ç»“æ„éªŒè¯:")
        required_fields = ["chapter", "persons", "events", "dig_events", "recall_events"]
        for field in required_fields:
            exists = "âœ”ï¸" if field in data else "âŒ"
            print(f"{exists} {field}: {type(data.get(field))}")

    async def _write_and_save(self, combined_data, chapter_num, article_type):
        writer = self.novel_writer if article_type == "novel" else self.script_writer
        print(f"âœï¸ å¼€å§‹ç”Ÿæˆç¬¬{chapter_num}ç«  {article_type}...")

        try:
            # è°ƒç”¨å†™ä½œæ™ºèƒ½ä½“
            # write_result = await writer.run(task=combined_data)
            write_result = await writer.a_run(task=combined_data)
            # print(write_result.messages)
            print("\n======================\n")
            print(f"âœï¸ ç¬¬{chapter_num}ç«  {article_type}ç”Ÿæˆå®Œæˆ")
            print(write_result)

            # æå–è¾“å‡º
            raw_output = extract_llm_content(write_result)

            # æ‰“å°åŸå§‹è¾“å‡º
            print("\nğŸ’¡ å†™ä½œAgentåŸå§‹è¾“å‡º:")
            print(raw_output)

            # ç§»é™¤Markdownä»£ç å—
            output_text = strip_markdown_codeblock(raw_output)
            output_text = output_text.strip()  # æ¸…ç†é¦–å°¾ç©ºç™½

            # éªŒè¯æå–ç»“æœï¼ˆå¢åŠ æ˜ç¡®é•¿åº¦æ£€æŸ¥ï¼‰
            if not output_text or len(output_text) < 10:  # é¿å…æçŸ­æ— æ•ˆå†…å®¹
                raise ValueError(
                    f"æå–çš„æ–‡æœ¬å†…å®¹æ— æ•ˆ "
                    f"| åŸå§‹é•¿åº¦: {len(raw_output)} "
                    f"| æ¸…ç†åé•¿åº¦: {len(output_text)}"
                )

            # ä¿å­˜æ–‡ä»¶
            ext = ".txt" if article_type == "novel" else ".md"
            filename = f"chapter_{chapter_num}_{article_type}{ext}"
            self._save_text(output_text, filename)
            print(f"ğŸ“¦ å·²ä¿å­˜è‡³: {os.path.join(self.save_dir, filename)}")

            return output_text

        except Exception as e:
            print(f"âš ï¸ å†™ä½œå¤±è´¥: {str(e)}")
            # ä¿å­˜å®Œæ•´è°ƒè¯•ä¿¡æ¯
            debug_info = (
                f"é”™è¯¯: {str(e)}\n"
                f"åŸå§‹ç»“æœç±»å‹: {type(write_result)}\n"
                f"åŸå§‹ç»“æœå†…å®¹: {str(write_result)}\n"
                f"extract_llm_contentè¾“å‡º: {raw_output}\n"
                f"stripåå†…å®¹: {output_text if 'output_text' in locals() else 'æœªå®šä¹‰'}"
            )
            self._save_text(debug_info, f"chapter_{chapter_num}_debug.txt")
            return ""

    def _save_text(self, content, filename):
        """
        ä¿å­˜æ–‡æœ¬å†…å®¹åˆ°æŒ‡å®šæ–‡ä»¶

        :param content: æ–‡æœ¬å†…å®¹
        :param filename: ä¿å­˜çš„æ–‡ä»¶å
        """
        os.makedirs(self.save_dir, exist_ok=True)
        full_path = os.path.join(self.save_dir, filename)

        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"ğŸ“¦ å·²ä¿å­˜è‡³: {full_path}")

    async def run_single_chapter(self, chapter_file, article_type="novel"):
        """
        å¤„ç†å•ä¸ªç« èŠ‚çš„å®Œæ•´æµç¨‹

        è¾“å…¥:
            chapter_file: ç« èŠ‚æ–‡ä»¶åï¼ˆå¦‚chapter1.jsonï¼‰
            article_type: æ–‡æœ¬ç±»å‹ï¼ˆnovel/scriptï¼‰

        è¾“å‡º:
            ç”Ÿæˆçš„ç« èŠ‚æ–‡æœ¬å†…å®¹
        """
        # 1. åŠ è½½å½“å‰ç« èŠ‚æ•°æ®
        current_data = self._load_current_chapter(chapter_file)
        chapter_num = current_data.get("chapter", "unknown")

        # 2. ä¼ç¬”å’Œå›å¿†åˆ†æ
        dig_resp, dig_data = await self._need_dig_and_load(current_data, chapter_file)
        recall_resp, recall_data = await self._need_recall_and_load(current_data, chapter_file)

        # 3. æ•°æ®æ•´åˆ
        combined_data = await self._combine_plans(current_data, dig_data, recall_data)

        # 4. å†™ä½œå¹¶ä¿å­˜
        return await self._write_and_save(combined_data, chapter_num, article_type)

    async def run_all_chapters(self, article_type="novel"):
        """
        å¤„ç†æ‰€æœ‰ç« èŠ‚ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰

        :param article_type: æ–‡æœ¬ç±»å‹ï¼ˆnovel/scriptï¼‰
        """
        all_files = sorted([
            f for f in os.listdir(self.chapters_dir)
            if f.endswith('.json') and f.startswith(('chapter', 'Chapter'))
        ])

        if not all_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚æ–‡ä»¶")
            return

        print(f"ğŸ“‘ å…±å‘ç° {len(all_files)} ä¸ªç« èŠ‚æ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
        for i, chapter_file in enumerate(all_files, 1):
            print(f"\n===== å¤„ç†ç¬¬{i}/{len(all_files)}ç« : {chapter_file} =====")
            await self.run_single_chapter(chapter_file, article_type)

    async def run(self, article_type="novel"):
        """
        å¯åŠ¨å®Œæ•´å†™ä½œæµç¨‹

        :param article_type: æ–‡æœ¬ç±»å‹ï¼ˆnovel/scriptï¼‰
        """
        # 1. éªŒè¯è¾“å…¥ç±»å‹
        article_type = self._validate_article_type(article_type)

        # 2. åˆå§‹åŒ–æ™ºèƒ½ä½“
        self._create_agents()

        # 3. å¤„ç†æ‰€æœ‰ç« èŠ‚
        await self.run_all_chapters(article_type)

        print("\nğŸ‰ æ‰€æœ‰ç« èŠ‚å¤„ç†å®Œæˆï¼")


# # è¿è¡Œç¤ºä¾‹
# if __name__ == '__main__':
#     import asyncio
#     from dotenv import load_dotenv
#     from Resource.llmclient import LLMClientManager

#     # åŠ è½½ç¯å¢ƒå˜é‡
#     load_dotenv()


#     async def main():
#         # é…ç½®è·¯å¾„
#         project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
#         chapters_dir = os.path.join(project_root, "Resource", "memory", "story_plan")

#         # è·å–æ¨¡å‹å®¢æˆ·ç«¯å’ŒNeo4jå¯†ç 
#         llm_client = LLMClientManager().get_client("deepseek-v3")
#         neo4j_password = os.getenv("NEO4J_PASSWORD")

#         # åˆå§‹åŒ–å¹¶è¿è¡Œå·¥ä½œæµ
#         workflow = WritingWorkflow(
#             model_client=llm_client,
#             chapters_dir=chapters_dir,
#             neo4j_password=neo4j_password
#         )
#         await workflow.run(article_type="novel")  # å¯åˆ‡æ¢ä¸º"script"


#     asyncio.run(main())
