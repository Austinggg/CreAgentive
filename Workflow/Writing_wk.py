import os
import json
from Resource.tools.strip_markdown_codeblock import strip_markdown_codeblock
from Agent.WriteAgent import create_agents
from Resource.tools.extract_llm_content import extract_llm_content
from autogen_agentchat.agents import AssistantAgent
from autogen_core.model_context import UnboundedChatCompletionContext
from Agent.MemoryAgent import MemoryAgent
from Resource.tools.read_json import read_json

import re

class WritingWorkflow:
    """
    å†™ä½œä½œæ–‡æ¡£å·¥ä½œæµç±»ï¼Œè´Ÿè´£åè°ƒå„æ™ºèƒ½ä½“å®Œæˆä»ç« èŠ‚åˆ†æåˆ°æœ€ç»ˆæ–‡æœ¬ç”Ÿæˆçš„å…¨æµç¨‹
    æ ¸å¿ƒåŠŸèƒ½ï¼šå¤„ç†ç« èŠ‚JSONæ•°æ®ã€è°ƒç”¨æ™ºèƒ½ä½“è¿›è¡Œä¼ç¬”æŒ–æ˜ä¸å›å¿†æ£€ç´¢ã€æ•´åˆæ•°æ®å¹¶ç”Ÿæˆå°è¯´/å‰§æœ¬
    """

    def __init__(self, model_client):
        """
        åˆå§‹åŒ–å·¥ä½œæµå‚æ•°
        :param model_client: è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆå¦‚DeepSeekï¼‰ï¼Œç”¨äºæ™ºèƒ½ä½“è°ƒç”¨
    """
        self.model_client = model_client 
        self.chapters_dir = os.path.join("Resource", "memory", "story_plan")
        self.save_dir = os.path.join("Resource", "story")
        self.current_chapter = 0
        self.chapter_count = 0
        self.memory_agent = MemoryAgent()

        # æ™ºèƒ½ä½“åˆå§‹åŒ–æ ‡è®°
        self.agents_initialized = False

    def _create_agents(self):
        """
        åˆ›å»ºå¹¶åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„æ™ºèƒ½ä½“
        æ™ºèƒ½ä½“åˆ—è¡¨ï¼š
        - memAgent: å†…å­˜ç®¡ç†æ™ºèƒ½ä½“
        - diggerAgent: ä¼ç¬”æŒ–æ˜æ™ºèƒ½ä½“
        - recallAgent: å›å¿†æ£€ç´¢æ™ºèƒ½ä½“
        - novel_writer: å°è¯´å†™ä½œæ™ºèƒ½ä½“
        - script_writer: å‰§æœ¬å†™ä½œæ™ºèƒ½ä½“
        """
        if self.agents_initialized:
            return  # é¿å…é‡å¤åˆå§‹åŒ–

        agents = create_agents(self.model_client)
        self.diggerAgent = agents["diggerAgent"]
        self.recallAgent = agents["recallAgent"]
        self.novel_writer = agents["novel_writer"]
        self.script_writer = agents["script_writer"]
        self.agents_initialized = True
        print("âœ… æ‰€æœ‰æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")

    def _validate_article_type(self, article_type):
        """
        éªŒè¯å†™ä½œç±»å‹åˆæ³•æ€§

        :param article_type: æ–‡ç« ç±»å‹ï¼Œæ”¯æŒ"novel"ï¼ˆå°è¯´ï¼‰æˆ–"script"ï¼ˆå‰§æœ¬ï¼‰
        :return: å°å†™çš„åˆæ³•ç±»å‹
        :raises AssertionError: ç±»å‹ä¸åˆæ³•æ—¶æŠ›å‡º
        """
        article_type = article_type.lower()
        assert article_type in ["novel", "script"], "æ–‡ç« ç±»å‹å¿…é¡»ä¸º 'novel' æˆ– 'script'"
        return article_type

    def _load_current_chapter(self, current_chapter_file):
        """
        åŠ è½½å½“å‰ç« èŠ‚çš„JSONæ•°æ®

        :param current_chapter_file: ç« èŠ‚æ–‡ä»¶åï¼ˆå¸¦.jsonæ‰©å±•åï¼‰
        :return: ç« èŠ‚æ•°æ®å­—å…¸ï¼Œæ ¼å¼å‚è€ƒchapter1.json
        """
        current_path = os.path.join(self.chapters_dir, current_chapter_file)
        print(f"ğŸ“– åŠ è½½ç« èŠ‚æ–‡ä»¶: {current_path}")
        data = read_json(current_path)

        return data

    async def _need_recall_and_load(self, current_data):
        print("\n" + "=" * 50)
        print("ğŸ” å¼€å§‹åˆ†äººç‰©å›å¿†æ£€ç´¢æµç¨‹")

        # è·å–æ‰€æœ‰äººç‰©
        characters = current_data.get("characters", [])
        all_recall_events = []

        for character in characters:
            char_id = character["id"]
            print(f"\nğŸ‘¤ å¤„ç†äººç‰©: {character.get('name')} ({char_id})")

            # è·å–è¯¥äººç‰©åœ¨å‰åºç« èŠ‚çš„äº‹ä»¶
            prev_events = self.memory_agent.get_previous_chapters_events(
                character_id=char_id,
                current_chapter=current_data["chapter"]
            )
            print(f"prev_events: {prev_events}")
            print(f"prev_eventsæ•°é‡: {len(prev_events)}")

            if not prev_events:
                print(f"âš ï¸ äººç‰© {character.get('name')} æ— å‰åºç« èŠ‚äº‹ä»¶")
                continue

            # æ„å»ºåˆ†äººç‰©è¾“å…¥æ•°æ®
            input_data = {
                "current_character": character,
                "current_events": [
                    e for e in current_data.get("events", [])
                    if char_id in e.get("participants", [])
                ],
                "past_events": prev_events
            }
            print(f"input_data: {input_data}")

            # è°ƒç”¨å›å¿†Agent
            recall_result = await self.recallAgent.a_run(task=input_data)
            # æ¸…ç©º recallAgent çš„ä¸Šä¸‹æ–‡
            await self.recallAgent.model_context.clear()
            raw_output = extract_llm_content(recall_result)
            print(f"raw_output: {raw_output}")

            try:
                recall_resp = json.loads(strip_markdown_codeblock(raw_output))
                if recall_resp.get("need_recall") == "Yes":
                    print(f"âœ… éœ€è¦ä¸º {character.get('name')} æ·»åŠ å›å¿†:")
                    for pos in recall_resp.get("positions", []):
                        event_details = self.memory_agent.get_event_details(pos["id"])
                        if event_details:
                            event_details["related_character"] = char_id
                            event_details["recall_reason"] = pos["reason"]
                            all_recall_events.append(event_details)
            except Exception as e:
                print(f"âŒ å¤„ç†äººç‰© {character.get('name')} å›å¿†å¤±è´¥: {str(e)}")

        return {"need_recall": "Yes" if all_recall_events else "No"}, all_recall_events

    async def _need_dig_and_load(self, current_data):
        print("\n" + "=" * 50)
        print("ğŸ”® å¼€å§‹ä¼ç¬”äº‹ä»¶æ£€ç´¢æµç¨‹")

        # è·å–æ‰€æœ‰åç»­ç« èŠ‚äº‹ä»¶ï¼ˆä¸é™å®šäººç‰©ï¼‰
        next_events = self.memory_agent.get_next_chapters_events(
            current_chapter=current_data["chapter"],
            end_chapter=self.chapter_count  # æŸ¥çœ‹åç»­5ç« 
        )
        print("next_events:", next_events)

        if not next_events:
            print("â„¹ï¸ æ— åç»­ç« èŠ‚äº‹ä»¶å¯ä¾›æŒ–æ˜")
            return {"need_dig": "No"}, []

        # æ„å»ºè¾“å…¥æ•°æ®
        input_data = {
            "current_chapter": current_data,
            "future_events": next_events
        }

        # è°ƒç”¨ä¼ç¬”Agent
        dig_result = await self.diggerAgent.a_run(task=input_data)
        # æ¸…ç©º diggerAgent ä¸Šä¸‹æ–‡
        await self.diggerAgent.model_context.clear()
        raw_output = extract_llm_content(dig_result)

        try:
            dig_resp = json.loads(strip_markdown_codeblock(raw_output))
            dig_events = []
            if dig_resp.get("need_dig") == "Yes":
                for pos in dig_resp.get("positions", []):
                    event_details = self.memory_agent.get_event_details(pos["id"])
                    if event_details:
                        dig_events.append(event_details)
                        # è¯¥å‡½æ•°è¿”å›çš„å†…å®¹dig_respæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æ˜¯å¦éœ€è¦æŒ–æ˜ä¼ç¬”çš„æ ‡å¿—å’Œå…·ä½“ä½ç½®ï¼Œ
                        # æ¯”å¦‚{"need_dig": "Yes", "positions": [{"id": "event123", "reason": "Foreshadowing for climax"}]}
                        # å…¶ä¸­positionsæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«äº†éœ€è¦æŒ–æ˜ä¼ç¬”çš„äº‹ä»¶IDå’ŒæŒ–æ˜ç†ç”±ã€‚
                        # è¿”å›çš„dig_eventsæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«äº†ä»Neo4jæ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°çš„å…·ä½“ä¼ç¬”äº‹ä»¶çš„è¯¦ç»†ä¿¡æ¯ï¼Œ
                        # æ¯”å¦‚[{"id": "event123", "description": "A mysterious stranger appears", ...}]ã€‚

            return dig_resp, dig_events
        except Exception as e:
            print(f"âŒ ä¼ç¬”åˆ†æå¤±è´¥: {str(e)}")
            return {"need_dig": "No"}, []

    async def _combine_plans(self, current_data, dig_events, recall_events):
        """
        å®Œæ•´æ•´åˆå½“å‰ç« èŠ‚æ•°æ®ä¸ä¼ç¬”/å›å¿†äº‹ä»¶

        å‚æ•°:
            current_data: å½“å‰ç« èŠ‚å®Œæ•´æ•°æ®(åŒ…å«characters/relationships/scenes/eventsç­‰)
            dig_events: ä»åç»­ç« èŠ‚æå–çš„å®Œæ•´ä¼ç¬”äº‹ä»¶åˆ—è¡¨
            recall_events: ä»å‰åºç« èŠ‚æå–çš„å®Œæ•´å›å¿†äº‹ä»¶åˆ—è¡¨

        è¿”å›:
            æ•´åˆåçš„å®Œæ•´ç« èŠ‚æ•°æ®ï¼Œä¿æŒåŸå§‹ç»“æ„å¹¶æ·»åŠ dig_eventså’Œrecall_events
        """
        print("\n" + "=" * 50)
        print("ğŸ§© å¼€å§‹å®Œæ•´æ•°æ®æ•´åˆ")

        # 1. æ·±æ‹·è´å½“å‰ç« èŠ‚æ•°æ®
        combined = json.loads(json.dumps(current_data))

        # 2. æ·»åŠ å®Œæ•´äº‹ä»¶ä¿¡æ¯
        combined["dig_events"] = []
        combined["recall_events"] = []

        # 3. å¤„ç†ä¼ç¬”äº‹ä»¶ï¼ˆä»åç»­ç« èŠ‚æå–çš„å®Œæ•´äº‹ä»¶ï¼‰
        for event in dig_events or []:
            if isinstance(event, dict):
                # è¡¥å……å¿…è¦å­—æ®µï¼ˆå¦‚æœNeo4jæŸ¥è¯¢ç»“æœç¼ºå°‘ï¼‰
                event.setdefault("source_type", "dig")
                combined["dig_events"].append(event)

        # 4. å¤„ç†å›å¿†äº‹ä»¶ï¼ˆä»å‰åºç« èŠ‚æå–çš„å®Œæ•´äº‹ä»¶ï¼‰
        for event in recall_events or []:
            if isinstance(event, dict):
                event.setdefault("source_type", "recall")
                combined["recall_events"].append(event)

        # 5. ä¸åˆå§‹åŒ–è®¾å®šç»“åˆ
        init_data = self._load_current_chapter("chapter_0.json")
        combined = {
            "title": init_data["title"],  # å°è¯´æ ‡é¢˜
            "background": init_data["background"],  # ä¸–ç•Œè§‚è®¾å®š
            "init_relationships": init_data["relationships"],
            **current_data,  # å½“å‰ç« èŠ‚æ•°æ®
            "dig_events": dig_events or [],
            "recall_events": recall_events or []
        }

        # 6. æ‰“å°è¯¦ç»†æ•´åˆæŠ¥å‘Š
        self._print_integration_details(combined)

        return combined

    def _print_integration_details(self, data):
        """æ‰“å°è¯¦ç»†çš„æ•´åˆç»“æœ"""
        print("\nğŸ“Š æ•´åˆè¯¦æƒ…æŠ¥å‘Š")
        print(f"=== ç« èŠ‚ {data.get('chapter', 'æœªçŸ¥')} ===")

        print("\nğŸ“Œ åŸå§‹è®¾å®š:")
        print(f"- é¢˜ç›®: {len(data.get('title', []))}")
        print(f"- èƒŒæ™¯: {len(data.get('background', []))}")

        # åŸå§‹æ•°æ®ç»Ÿè®¡
        print("\nğŸ“Œ ç« èŠ‚æ•°æ®:")
        print(f"- äººç‰©: {len(data.get('characters', []))}")
        print(f"- å…³ç³»: {len(data.get('relationships', []))}")
        print(f"- åœºæ™¯: {len(data.get('scenes', []))}")
        print(f"- ä¸»äº‹ä»¶: {len(data.get('events', []))}")

        # ä¼ç¬”äº‹ä»¶è¯¦æƒ…
        print("\nğŸ”® ä¼ç¬”äº‹ä»¶:")
        for event in data.get("dig_events", [])[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ªå®Œæ•´äº‹ä»¶
            print(json.dumps(event, indent=2, ensure_ascii=False))

        # å›å¿†äº‹ä»¶è¯¦æƒ…
        print("\nğŸ“œ å›å¿†äº‹ä»¶:")
        for event in data.get("recall_events", [])[:2]:
            print(json.dumps(event, indent=2, ensure_ascii=False))

        # å®Œæ•´æ•°æ®ç»“æ„éªŒè¯
        print("\nâœ… æœ€ç»ˆæ•°æ®ç»“æ„éªŒè¯:")
        required_fields = ["chapter", "characters", "events", "dig_events", "recall_events"]
        for field in required_fields:
            exists = "âœ”ï¸" if field in data else "âŒ"
            print(f"{exists} {field}: {type(data.get(field))}")

    async def _write_and_save(self, combined_data, chapter_num, article_type):
        
        # é€‰æ‹©
        writer = self.novel_writer if article_type == "novel" else self.script_writer
        print(f"âœï¸ å¼€å§‹ç”Ÿæˆç¬¬{chapter_num}ç«  {article_type}...")

        try:
            # æ ¹æ®æ–‡ç« ä½“è£è°ƒç”¨å¯¹åº”ç±»åˆ«çš„å†™ä½œæ™ºèƒ½ä½“

            write_result = await writer.a_run(task=combined_data)
            # è°ƒç”¨å®Œæˆåè¦æ±‚æ¸…ç©ºè¯¥ agent çš„ä¸Šä¸‹æ–‡
            print("è°ƒç”¨å†™ä½œæ™ºèƒ½ä½“ç»“æŸ")
            await self.novel_writer.model_context.clear()
            await self.script_writer.model_context.clear()


            # print(write_result.messages)
            print("\n======================\n")
            print(f"âœï¸ ç¬¬{chapter_num}ç«  {article_type}ç”Ÿæˆå®Œæˆ")
            print(write_result)

            # æå–è¾“å‡º
            raw_output = extract_llm_content(write_result)

            # æ‰“å°åŸå§‹è¾“å‡º
            print("\nğŸ’¡ å†™ä½œAgentåŸå§‹è¾“å‡º:")
            print(raw_output)

            # ç§»é™¤Markdownä»£ç å—
            output_text = strip_markdown_codeblock(raw_output)
            output_text = output_text.strip()  # æ¸…ç†é¦–å°¾ç©ºç™½

            chapter_title = combined_data.get("chapter_title", f"ç¬¬{chapter_num}ç« ")
            output_text = f"{chapter_title}\n\n{output_text}"  # åœ¨ç”Ÿæˆå†…å®¹å‰æ·»åŠ æ ‡é¢˜

            # éªŒè¯æå–ç»“æœï¼ˆå¢åŠ æ˜ç¡®é•¿åº¦æ£€æŸ¥ï¼‰
            if not output_text or len(output_text) < 10:  # é¿å…æçŸ­æ— æ•ˆå†…å®¹
                raise ValueError(
                    f"æå–çš„æ–‡æœ¬å†…å®¹æ— æ•ˆ "
                    f"| åŸå§‹é•¿åº¦: {len(raw_output)} "
                    f"| æ¸…ç†åé•¿åº¦: {len(output_text)}"
                )

            # ä¿å­˜æ–‡ä»¶
            ext = ".txt" if article_type == "novel" else ".md"
            filename = f"chapter_{chapter_num}_{article_type}{ext}"
            self._save_text(output_text, filename)
            print(f"ğŸ“¦ å·²ä¿å­˜è‡³: {os.path.join(self.save_dir, filename)}")

            return output_text

        except Exception as e:
            print(f"âš ï¸ å†™ä½œå¤±è´¥: {str(e)}")
            # ä¿å­˜å®Œæ•´è°ƒè¯•ä¿¡æ¯
            debug_info = (
                f"é”™è¯¯: {str(e)}\n"
                f"åŸå§‹ç»“æœç±»å‹: {type(write_result)}\n"
                f"åŸå§‹ç»“æœå†…å®¹: {str(write_result)}\n"
                f"extract_llm_contentè¾“å‡º: {raw_output}\n"
                f"stripåå†…å®¹: {output_text if 'output_text' in locals() else 'æœªå®šä¹‰'}"
            )
            self._save_text(debug_info, f"chapter_{chapter_num}_debug.txt")
            return ""

    def _save_text(self, content, filename):
        """
        ä¿å­˜æ–‡æœ¬å†…å®¹åˆ°æŒ‡å®šæ–‡ä»¶

        :param content: æ–‡æœ¬å†…å®¹
        :param filename: ä¿å­˜çš„æ–‡ä»¶å
        """
        os.makedirs(self.save_dir, exist_ok=True)
        full_path = os.path.join(self.save_dir, filename)

        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"ğŸ“¦ å·²ä¿å­˜è‡³: {full_path}")

    async def run_single_chapter(self, chapter_file, article_type="novel"):
        """
        å¤„ç†å•ä¸ªç« èŠ‚çš„å®Œæ•´æµç¨‹

        è¾“å…¥:
            chapter_file: ç« èŠ‚æ–‡ä»¶åï¼ˆå¦‚chapter1.jsonï¼‰
            article_type: æ–‡æœ¬ç±»å‹ï¼ˆnovel/scriptï¼‰

        è¾“å‡º:
            ç”Ÿæˆçš„ç« èŠ‚æ–‡æœ¬å†…å®¹
        """
        # 1. åŠ è½½å½“å‰ç« èŠ‚æ•°æ®
        current_data = self._load_current_chapter(chapter_file)  # åŠ è½½ç« èŠ‚æ•°æ®
        chapter_num = current_data.get("chapter", "unknown")  # è·å–ç« èŠ‚ç¼–å·

        # 2. ä¼ç¬”å’Œå›å¿†åˆ†æ
        dig_resp, dig_data = await self._need_dig_and_load(current_data)
        # dig_respå’Œdig_dataçš„
        recall_resp, recall_data = await self._need_recall_and_load(current_data)
        print(dig_resp)
        print(dig_data)
        print(recall_resp)
        print(recall_data)

        # 3. æ•°æ®æ•´åˆ
        # è¿™é‡Œçš„_combine_planså‡½æ•°ä¼šå°†å½“å‰ç« èŠ‚æ•°æ®ä¸æŒ–æ˜åˆ°çš„ä¼ç¬”äº‹ä»¶å’Œå›å¿†äº‹ä»¶è¿›è¡Œæ•´åˆ
        combined_data = await self._combine_plans(current_data, dig_data, recall_data)
        print(combined_data)

        # 4. å†™ä½œå¹¶ä¿å­˜
        return await self._write_and_save(combined_data, chapter_num, article_type)

    async def run_all_chapters(self, article_type="novel"):
        """
        å¤„ç†æ‰€æœ‰ç« èŠ‚ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰
        :param article_type: æ–‡æœ¬ç±»å‹ï¼ˆnovel/scriptï¼‰
        """

        print(f"æ£€æŸ¥ç›®å½•: {self.chapters_dir}")
        print(f"ç›®å½•å†…å®¹: {os.listdir(self.chapters_dir)}")

        # è·å–æ‰€æœ‰ç« èŠ‚æ–‡ä»¶å¹¶æ’é™¤chapter_0.json
        all_files = [
            f for f in os.listdir(self.chapters_dir)
            if f.endswith('.json')
               and f != "chapter_0.json"  # æ›´å®½æ¾çš„æ¡ä»¶
        ]

        # æŒ‰ç« èŠ‚æ•°å­—æ’åºï¼ˆå‡è®¾æ–‡ä»¶åæ ¼å¼ä¸ºchapterX.jsonï¼‰
        all_files = sorted(all_files, key=lambda x: int(re.search(r'(\d+)', x).group(1)))

        self.chapter_count = len(all_files)
        print(f"ğŸ“‘ å…±å‘ç° {len(all_files)} ä¸ªç« èŠ‚æ–‡ä»¶ï¼ˆè·³è¿‡chapter_0.jsonï¼‰ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
        # ç°åœ¨å¼€å§‹å¤„ç†æ¯ä¸ªç« èŠ‚ï¼Œè°ƒç”¨å‡½æ•°run_single_chapterè¿›è¡Œå¤„ç†
        for i, chapter_file in enumerate(all_files, 1):
            self.current_chapter = i
            print(f"\n===== å¤„ç†ç¬¬{i}/{len(all_files)}ç« : {chapter_file} =====")
            await self.run_single_chapter(chapter_file, article_type)


    async def run(self, article_type="novel"):
        """
        å¯åŠ¨å®Œæ•´å†™ä½œæµç¨‹
        :param article_type: æ–‡æœ¬ç±»å‹ï¼ˆnovel/scriptï¼‰
        """
        # 1. éªŒè¯è¾“å…¥ç±»å‹
        article_type = self._validate_article_type(article_type)

        # 2. åˆå§‹åŒ–æ™ºèƒ½ä½“
        self._create_agents()
        if self.novel_writer is None:
            raise ValueError("å°è¯´å†™ä½œæ™ºèƒ½ä½“æœªæ­£ç¡®åˆå§‹åŒ–")

        # 3. å¤„ç†æ‰€æœ‰ç« èŠ‚
        await self.run_all_chapters(article_type)

        print("\nğŸ‰ æ‰€æœ‰ç« èŠ‚å¤„ç†å®Œæˆï¼")


# # è¿è¡Œç¤ºä¾‹
# if __name__ == '__main__':
#     import asyncio
#     from dotenv import load_dotenv
#     from Resource.llmclient import LLMClientManager

#     # åŠ è½½ç¯å¢ƒå˜é‡
#     load_dotenv()


#     async def main():
#         # é…ç½®è·¯å¾„
#         project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
#         chapters_dir = os.path.join(project_root, "Resource", "memory", "story_plan")

#         # è·å–æ¨¡å‹å®¢æˆ·ç«¯å’ŒNeo4jå¯†ç 
#         llm_client = LLMClientManager().get_client("deepseek-v3")
#         neo4j_password = os.getenv("NEO4J_PASSWORD")

#         # åˆå§‹åŒ–å¹¶è¿è¡Œå·¥ä½œæµ
#         workflow = WritingWorkflow(
#             model_client=llm_client,
#             chapters_dir=chapters_dir,
#             neo4j_password=neo4j_password
#         )
#         await workflow.run(article_type="novel")  # å¯åˆ‡æ¢ä¸º"script"


#     asyncio.run(main())
