from Agent.WriteAgent import create_agents
import os
import json
from datetime import datetime
from Resource.tools.strip_markdown_codeblock import strip_markdown_codeblock
from Resource.llmclient import LLMClientManager


class WritingWorkflow:
    def __init__(self, model_client, chapters_dir, save_dir=None):
        """
        :param model_client: è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äºåˆ›å»ºå’Œè°ƒç”¨å„ä¸ªæ™ºèƒ½ä½“
        :param chapters_dir: å­˜æ”¾ç« èŠ‚ JSON æ–‡ä»¶çš„ç›®å½•è·¯å¾„
        :param save_dir: å†™ä½œè¾“å‡ºç›®å½•ï¼Œé»˜è®¤åœ¨ chapters_dir/output
        """
        self.model_client = model_client
        self.chapters_dir = chapters_dir
        # å¦‚æœæœªæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œåˆ™åœ¨ chapters_dir ä¸‹åˆ›å»º å­ç›®å½•
        self.save_dir = 'Resource\story' # æ•…äº‹å­˜å‚¨æºè·¯å¾„

        # æ™ºèƒ½ä½“å ä½ç¬¦ï¼Œåœ¨ _create_agents() ä¸­åˆå§‹åŒ–
        # self.diggerAgent = None      # æŒ–å‘åˆ¤æ–­
        # self.recallAgent = None      # å›å¿†åˆ¤æ–­
        # self.combinerAgent = None    # åˆå¹¶æ•°æ®
        # self.writer = None           # å†™ä½œè¾“å‡º

    def _create_agents(self):
        """
        åˆ›å»ºå†™ä½œæµç¨‹æ‰€éœ€çš„æ™ºèƒ½ä½“ï¼šæŒ–å‘ Agentã€å›å¿† Agentã€åˆå¹¶ Agentã€å†™ä½œ Agent
        """
        agents = create_agents(self.model_client)
        self.diggerAgent = agents["diggerAgent"] # æŒ–å‘ Agentç”¨äºå¯åŠ¨åˆ›ä½œï¼Œè®¾å®šæ•…äº‹å¤§çº²
        self.recallAgent = agents["recallAgent"] # å›å¿† Agentè´Ÿè´£æ ¹æ®æ•…äº‹å¤§çº²å›æº¯ç›¸å…³æƒ…èŠ‚å’ŒèƒŒæ™¯ä¿¡æ¯
        self.combinerAgent = agents["combinerAgent"] # åˆå¹¶ Agentå°†ä¸åŒæ¥æºçš„ä¿¡æ¯æ•´åˆæˆè¿è´¯çš„å†…å®¹
        self.writer = agents["writer"] # å†™ä½œ Agentæ‰§è¡Œå®é™…çš„å†™ä½œä»»åŠ¡ï¼Œäº§å‡ºæ–‡æœ¬å†…å®¹

    def _validate_article_type(self, article_type="novel"):
        """
        éªŒè¯å†™ä½œç±»å‹æ˜¯å¦åˆæ³•
        :param article_type: æ–‡ç« ç±»å‹ï¼Œ"novel"ï¼ˆå°è¯´ï¼‰æˆ– "script"ï¼ˆå‰§æœ¬ï¼‰
        :return: æ ¡éªŒåçš„æ–‡ç« ç±»å‹ï¼ˆå°å†™ï¼‰
        :raises: AssertionError å¦‚æœç±»å‹ä¸åˆæ³•
        """
        article_type = article_type.lower()
        assert article_type in ["novel", "script"], "æ–‡ç« ç±»å‹å¿…é¡»ä¸º 'novel' æˆ– 'script'"
        return article_type
    
    def _load_current_chapter(self, current_chapter_file):
        """
        åŠ è½½å½“å‰ç« èŠ‚çš„ JSON æ•°æ®
        :param current_chapter_file: å½“å‰ç« èŠ‚æ–‡ä»¶åï¼ˆå¸¦æ‰©å±•åï¼‰
        :return: è§£æåçš„ç« èŠ‚æ•°æ®
        """
        current_path = os.path.join(self.chapters_dir, current_chapter_file)
        print(f"ğŸ“– åŠ è½½å½“å‰ç« èŠ‚ï¼š{current_chapter_file}")
        return self._load_json(current_path)
    

    def _need_dig_and_load(self, current_data, current_chapter_file):
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æŒ–å‘ï¼Œå¹¶åŠ è½½åç»­ç« èŠ‚æ•°æ®
        :param current_data: å½“å‰ç« èŠ‚æ•°æ®
        :param current_chapter_file: å½“å‰ç« èŠ‚æ–‡ä»¶å
        :return: (need_dig, dig_data)
        """
        all_files = sorted(os.listdir(self.chapters_dir))
        is_last = current_chapter_file == all_files[-1]

        if is_last:
            print("ğŸ”’ æœ€åä¸€ç« ï¼Œæ— éœ€æŒ–å‘")
            return False, []

        print("ğŸ” åˆ¤æ–­æ˜¯å¦éœ€è¦â€˜æŒ–å‘â€™...")
        dig_resp = self.diggerAgent.run(current_data)
        need_dig = dig_resp.strip().lower() == 'yes'

        dig_data = []
        if need_dig:
            print("â›ï¸ éœ€è¦æŒ–å‘ï¼ŒåŠ è½½åç»­ç« èŠ‚...")
            for fname in all_files:
                if fname.endswith('.json') and fname > current_chapter_file:
                    dig_data.append(self._load_json(os.path.join(self.chapters_dir, fname)))

        return need_dig, dig_data
    
    def _need_recall_and_load(self, current_data, current_chapter_file):
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦å›å¿†ï¼Œå¹¶åŠ è½½å‰åºç« èŠ‚æ•°æ®
        :param current_data: å½“å‰ç« èŠ‚æ•°æ®
        :param current_chapter_file: å½“å‰ç« èŠ‚æ–‡ä»¶å
        :return: (need_recall, recall_data)
        """
        all_files = sorted(os.listdir(self.chapters_dir))
        is_first = current_chapter_file == all_files[0]

        if is_first:
            print("ğŸ”’ ç¬¬ä¸€ç« ï¼Œæ— éœ€å›å¿†")
            return False, []

        print("ğŸ” åˆ¤æ–­æ˜¯å¦éœ€è¦â€˜å›å¿†â€™...")
        recall_resp = self.recallAgent.run(current_data)
        need_recall = recall_resp.strip().lower() == 'yes'

        recall_data = []
        if need_recall:
            print("ğŸ”„ éœ€è¦å›å¿†ï¼ŒåŠ è½½å‰åºç« èŠ‚...")
            for fname in all_files:
                if fname.endswith('.json') and fname < current_chapter_file:
                    recall_data.append(self._load_json(os.path.join(self.chapters_dir, fname)))

        return need_recall, recall_data

    def _save_text(self, content, filename):
        """
        å°†å†™ä½œç»“æœä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶
        :param content: æ–‡æœ¬å†…å®¹
        :param filename: æ–‡ä»¶åï¼ˆå¸¦æ‰©å±•åï¼‰
        """
        os.makedirs(self.save_dir, exist_ok=True)
        full_path = os.path.join(self.save_dir, filename)
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“¦ æˆæœå·²ä¿å­˜è‡³ {full_path}")

    def run(self, current_chapter_file, article_type="novel"):  # "novel" or "script"
        """
        æ‰§è¡Œå†™ä½œæµç¨‹ï¼š
        1. éªŒè¯å†™ä½œç±»å‹
        2. åˆ›å»ºæ™ºèƒ½ä½“
        3. è¯»å–å½“å‰ç« èŠ‚ JSON
        4. åˆ¤æ–­æ˜¯å¦éœ€è¦â€˜æŒ–å‘â€™å’Œ/æˆ–â€˜å›å¿†â€™
        5. å¦‚éœ€æŒ–å‘åˆ™åŠ è½½åç»­ç« èŠ‚ï¼›å¦‚éœ€å›å¿†åˆ™åŠ è½½å‰åºç« èŠ‚
        6. å°†åŸæ–‡ã€æŒ–å‘ç»“æœã€å›å¿†ç»“æœç»Ÿä¸€ä¼ ç»™åˆå¹¶ Agent
        7. å†™ä½œå¹¶ä¿å­˜ç»“æœ

        :param current_chapter_file: å½“å‰ç« èŠ‚ JSON æ–‡ä»¶åï¼ˆç›¸å¯¹äº chapters_dirï¼‰
        :param article_type: å†™ä½œç±»å‹ï¼Œ"novel"ï¼ˆå°è¯´ï¼‰æˆ– "script"ï¼ˆå‰§æœ¬ï¼‰
        :return: æœ€ç»ˆå†™ä½œçš„æ–‡æœ¬å†…å®¹
        """
        
        # ---- æ­¥éª¤ 1ï¼šéªŒè¯å†™ä½œç±»å‹ ----
        print(f"ğŸš€ éªŒè¯å†™ä½œç±»å‹...")
        article_type = self._validate_article_type(article_type) # éªŒè¯å†™ä½œç±»å‹ï¼Œä¿å­˜å†™ä½œç±»å‹

        # ---- æ­¥éª¤ 2ï¼šåˆ›å»ºæ™ºèƒ½ä½“ ----
        print(f"ğŸš€ åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆ{article_type} æ¨¡å¼ï¼‰...")
        self._create_agents()


        # Todo: æ‰“åŒ…æˆå¾ªç¯ä»ç¬¬ä¸€ç« ä»¥æ­¤è¯»å–ï¼Œå†™ä½œ

        # ---- æ­¥éª¤ 3ï¼šè¯»å–å½“å‰ç« èŠ‚ JSON ----
        
        current_data = self._load_current_chapter(current_chapter_file)

        # ---- æ­¥éª¤ 4ï¼šæŒ–å‘ & å›å¿† åˆ¤æ–­ ----
        # å›å¿†åªåœ¨éç¬¬ä¸€ç« å¯ç”¨
        all_files = sorted(os.listdir(self.chapters_dir))
        is_first = current_chapter_file == all_files[0]
        if is_first:
            print("ğŸ”’ ç¬¬ä¸€ç« ï¼Œæ— éœ€å›å¿†")
            need_recall = False
        else:
            print("ğŸ” åˆ¤æ–­æ˜¯å¦éœ€è¦â€˜å›å¿†â€™...")
            recall_resp = self.recallAgent.run(current_data)
            need_recall = recall_resp.strip().lower() == 'yes'

        # æŒ–å‘åœ¨éæœ€åä¸€ç« å¯ç”¨ï¼Œæœ€åä¸€ç« æ— éœ€æŒ–å‘
        is_last = current_chapter_file == all_files[-1]
        if is_last:
            print("ğŸ”’ æœ€åä¸€ç« ï¼Œæ— éœ€æŒ–å‘")
            need_dig = False
        else:
            print("ğŸ” åˆ¤æ–­æ˜¯å¦éœ€è¦â€˜æŒ–å‘â€™...")
            dig_resp = self.diggerAgent.run(current_data)
            need_dig = dig_resp.strip().lower() == 'yes'

        # ---- æ­¥éª¤ 5ï¼šåŠ è½½å‰åºä¸åç»­ç« èŠ‚ ----
        recall_data = []
        dig_data = []
        all_files = sorted(os.listdir(self.chapters_dir))

        if need_recall:
            print("ğŸ”„ éœ€è¦å›å¿†ï¼ŒåŠ è½½å‰åºç« èŠ‚...")
            for fname in all_files:
                if fname.endswith('.json') and fname < current_chapter_file:
                    recall_data.append(self._load_json(os.path.join(self.chapters_dir, fname)))

        if need_dig:
            print("â›ï¸ éœ€è¦æŒ–å‘ï¼ŒåŠ è½½åç»­ç« èŠ‚...")
            for fname in all_files:
                if fname.endswith('.json') and fname > current_chapter_file:
                    dig_data.append(self._load_json(os.path.join(self.chapters_dir, fname)))

        # ---- æ­¥éª¤ 6ï¼šåˆå¹¶æ‰€æœ‰å†…å®¹ ----
        print("ğŸ”§ åˆå¹¶åŸæ–‡ã€å›å¿†å’ŒæŒ–å‘æ•°æ®...")
        merge_input = {
            "current": current_data,
            "recall": recall_data,
            "dig": dig_data
        }
        comb_resp = self.combinerAgent.run(merge_input)
        merged_data = json.loads(comb_resp)

        # ---- æ­¥éª¤ 7ï¼šå†™ä½œ & ä¿å­˜ ----
        print(f"âœï¸ å¼€å§‹å†™ä½œï¼Œç±»å‹ï¼š{article_type}...")
        write_prompt = {"type": article_type, "data": merged_data}
        write_resp = self.writer.run(write_prompt)
        output_text = strip_markdown_codeblock(write_resp)

        ext = ".md" if article_type == 'script' else '.txt'
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"output_{article_type}_{timestamp}{ext}"
        self._save_text(output_text, filename)

        return output_text


if __name__ == '__main__':
    

    client = LLMClientManager.get_client("DeepSeek-v3")
    workflow = WritingWorkflow(client, chapters_dir='./Resource/chapters')
    workflow.run('chapter_02.json', article_type='novel')
    print("å†™ä½œå®Œæˆï¼")
